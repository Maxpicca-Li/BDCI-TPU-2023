data:
  train_root: './datasets/2K_HR'
  test_root: './datasets/2K_HR_test'
  lr_crop_size: 200
model:
  upscale_factor: 4
  img_channels: 3 # 1 for Y, 3 for RGB  
training:
  iterations: 6000 # total number of iterations to train
  batch_size: 32
  val_interval: 200 # run validation after this # of iterations
  print_interval: 10 # print training log every # of iterations
  checkpoint_folder: 'models'
  optimizer:
    name: adam # sgd or adam
    lr: 1.0e-4
  scheduler:
    lr_decay: 0.9
    interval: 100 # decay lr every # of iteraitons
  resume: 'None' # path to checkpoint to resume from